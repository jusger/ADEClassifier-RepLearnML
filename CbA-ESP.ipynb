{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification-by-Analogy: Distributed Representations of Extracted Knowledge for Machine Learning of Plausible Drug Side-Effects\n",
    "## AMIA 2017\n",
    "Justin Mower, Devika Subramanian, Trevor Cohen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "At the github link where this notebook is hosted, there should be a zip file containing all of the necessary data files to regenerate the results of our recent JAMIA paper. Download and unzip the file, and then make sure the file paths are correct in this notebook. It is recommend to use the Anaconda Python distribution to regenerate these results, and an environment meeting all of the required packages can be created from the environment.yml file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sets\n",
    "#### EU-ADR\n",
    "\n",
    "The EU-ADR reference standard is comprised of 43 positive and 50 negative controls (93 combined) across 10 ADEs. Mitral valve disorders *only* have negative control examples in the reference set, but all other ADEs are represented by both. All drugs (except for nimesulide) and ADEs in the set have representations in the vector space utilized. The 10 ADEs are, written as queried in the vector space: \n",
    "1. **anaphylaxis**\n",
    "2. **aplastic\\_anemia**\n",
    "3. **erythema\\_multiforme**\n",
    "4. **diseases\\_of\\_mitral\\_valve**\n",
    "5. **neutropenia**\n",
    "6. **rhabdomyolysis**\n",
    "7. **acute\\_myocardial\\_infarction**\n",
    "8. **gastrointestinal\\_hemorrhage**\n",
    "9. **acute_kidney_insufficiency**\n",
    "10. **liver\\_failure,\\_acute**\n",
    "\n",
    "The startlist used with VectorStoreSubset is in startlists/euadrquery.txt. Labels corresponding to these queries are found in startlists/euadrreflabsandqueries.txt. The labels, order-matched to euadrquery.txt, is found in startlists/euadrlabels.txt. Binary vector output from VectorStoreSubset is found in subsetvecs/binary/euadrquery_subset.bin and subsetvecs/binary/psieuadr_subset.bin. The plaintext vectors are found in subsetvecs/text/euadrquery_subset.txt. The ordering is different between the euadrquery_subset.txt and the euadrquery.txt, so a dictionary generated from the euadrreflabsandqueries.txt to translate the new order with the appropriate labels was utilized.\n",
    "\n",
    "#### OMOP (Ryan et al)\n",
    "\n",
    "The OMOP reference standard published by Ryan et al is comprised of 165 positive and 234 negative controls (399 combined) across 4 ADEs. The 4 ADEs are, written here as they were queried in the vector space:\n",
    "1. **acute\\_myocardial\\_infarction**\n",
    "2. **gastrointestinal\\_hemorrhage**\n",
    "3. **acute\\_kidney\\_insufficiency**\n",
    "4. **liver\\_failure,\\_acute**\n",
    "\n",
    "Not all drugs are accounted for in the vector space. Specifically, darunavir (aka Prezista;Prezcobix) and sitagliptin (aka Januvia) have no representation in the vector space, or in the translated names I could find for them. Niacin was translated to nicotinic_acid. All other drugs were queried as-is in the reference standard supplementary material excel spreadsheet presented with the OMOP reference standard paper.\n",
    "\n",
    "As with the EU-ADR reference set, the startlist used with VectorStoreSubset is in startlists/OMOPquery.txt. Labels corresponding to these queries are found in startlists/OMOPlabsandqueries.txt. The labels, order-matched to OMOPquery.txt, is found in startlists/OMOPlabels.txt. Binary vector output from VectorStoreSubset is found in subsetvecs/binary/OMOPquery_subset.bin and subsetvecs/binary/psiomop_subset.bin. The plaintext vectors are found in subsetvecs/text/OMOPquery_subset.txt. The ordering is different between the OMOPquery_subset.txt and the OMOPquery.txt, so a dictionary generated from the OMOPreflabsandqueries.txt to translate the new order with the appropriate labels was utilized.\n",
    "\n",
    "#### SIDER Derived\n",
    "\n",
    "For the SIDER derived vectors, the full set of drugs was downloaded and put into composed query form with the four side-effects from OMOP (startlists/raw[ADE]siderquery.txt). For drugs that didn't have representation in the space, they were removed from the list (startlists/[ADE]siderquery.txt). Then, drugs that were in the OMOP reference standard were removed (noOMOP[ADE]siderquery.txt) and then high performance set MEDI indications were removed (noOMOPnoMEDI[ADE]sider.txt). These individual ADE lists were concatenated into startlists/noOMOPnoMEDIfullsider.txt). The MEDI indications from the high performance set can be found in startlists/medihpsindications.txt. This resulted in variable length lists for each side-effect, which their startlist can be found in startlists/noOMOPnoMEDIfullsider.txt. There is no corresponding label file for these, as ground-truth for our analysis isn't known. The binary vector output is from VectorStoreSubset is found in subsetvecs/binary/noOMOPnoMEDIfullsider_subset.bin. The plaintext vectors are found in subsetvecs/text/noOMOPnoMEDIfullsider_subset.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  bitarray import bitarray\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import LeaveOneOut, StratifiedKFold\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import HoverTool\n",
    "import matplotlib.pyplot as plt\n",
    "output_notebook() #for bokeh to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define some useful functions\n",
    "\n",
    "# Load Data from Raw Text\n",
    "# Expects QUERY|BINARYVECTOR; label file LABEL\\tQuery\n",
    "# Returns a df with Query, Label, Vectors\n",
    "def loaddata(inputfile, labelfile):\n",
    "    tmpvecs = []\n",
    "    tmpqueries = []\n",
    "    with open(inputfile, 'r') as infile:\n",
    "        infile.readline()#skip header row\n",
    "        for line in infile:\n",
    "            tmp = line.strip().split('|')\n",
    "            tmpvecs += [np.asarray(bitarray(tmp[1]), dtype=int)]\n",
    "            tmpqueries += [tmp[0]]\n",
    "        tmpdf = pd.DataFrame(np.asarray(tmpvecs))\n",
    "        tmpdf.columns = [str(x) for x in range(1, np.asarray(tmpvecs).shape[1]+1)]\n",
    "        tmpdf.insert(0, 'Query', tmpqueries)\n",
    "    labsdict = dict()\n",
    "    with open(labelfile,'r') as infile:\n",
    "        for line in infile:\n",
    "            tmp = line.strip().split('\\t')\n",
    "            labsdict[tmp[1]] = int(tmp[0])\n",
    "    tmpdf.insert(1, 'Label', [labsdict[x] for x in tmpqueries])\n",
    "    return tmpdf\n",
    "\n",
    "\n",
    "# Leave one out crossvalidation quick test\n",
    "def lootest(df):\n",
    "    preds = []\n",
    "    predprob = []\n",
    "    reals = []\n",
    "    vecs = np.asarray(df.iloc[:,2:])\n",
    "    labels = np.asarray(df.Label)\n",
    "    for train,test in LeaveOneOut().split(vecs):\n",
    "        model = LogisticRegression(penalty='l2')\n",
    "        model.fit(vecs[train], labels[train])\n",
    "        preds += [model.predict(vecs[test])]\n",
    "        predprob += [model.predict_proba(vecs[test])[:,1]]\n",
    "        reals += [labels[test]]\n",
    "    return(f1_score(reals, preds), roc_auc_score(reals, predprob))\n",
    "    \n",
    "# Stratified 5 Fold crossvalidation quick test\n",
    "# Returns overall F1 and ROC AUC for comparison to other research\n",
    "# That is, we don't compute fold to fold, but over the whole set\n",
    "def skftest(df):\n",
    "    reals = np.asarray([])\n",
    "    preds = np.asarray([])\n",
    "    predprob = np.asarray([])\n",
    "    vecs = np.asarray(df.iloc[:,2:])\n",
    "    labels = np.asarray(df.Label)\n",
    "    for train,test in StratifiedKFold(n_splits=5, shuffle=True).split(vecs, labels):\n",
    "        model = LogisticRegression(penalty='l2')\n",
    "        model.fit(vecs[train], labels[train])\n",
    "        predprob = np.append(predprob, model.predict_proba(vecs[test])[:,1])\n",
    "        reals = np.append(reals, labels[test])\n",
    "        preds = np.append(preds, model.predict(vecs[test]))\n",
    "    return(f1_score(reals, preds), roc_auc_score(reals, predprob))\n",
    "\n",
    "# kNN leave one out cross-validation quick test\n",
    "def looknntest(df, neighbors):\n",
    "    preds = []\n",
    "    predprob = []\n",
    "    reals = []\n",
    "    vecs = np.asarray(df.iloc[:,2:])\n",
    "    labels = np.asarray(df.Label)\n",
    "    for train,test in LeaveOneOut().split(vecs):\n",
    "        model = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "        model.fit(vecs[train], labels[train])\n",
    "        preds += [model.predict(vecs[test])]\n",
    "        predprob += [model.predict_proba(vecs[test])[:,1]]\n",
    "        reals += [labels[test]]\n",
    "    return(f1_score(reals, preds), roc_auc_score(reals, predprob))\n",
    "\n",
    "# kNN stratified 5 Fold cross-validation quick test\n",
    "# Returns overall F1 and ROC AUC for comparison to other research\n",
    "# That is, we don't compute fold to fold, but over the whole set\n",
    "def skfknntest(df, neighbors):\n",
    "    reals = np.asarray([])\n",
    "    preds = np.asarray([])\n",
    "    predprob = np.asarray([])\n",
    "    vecs = np.asarray(df.iloc[:,2:])\n",
    "    labels = np.asarray(df.Label)\n",
    "    for train,test in StratifiedKFold(n_splits=5, shuffle=True).split(vecs, labels):\n",
    "        model = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "        model.fit(vecs[train], labels[train])\n",
    "        predprob = np.append(predprob, model.predict_proba(vecs[test])[:,1])\n",
    "        reals = np.append(reals, labels[test])\n",
    "        preds = np.append(preds, model.predict(vecs[test]))\n",
    "    return(f1_score(reals, preds), roc_auc_score(reals, predprob))\n",
    "\n",
    "# Get the average performance across 100 runs for a given LR training model\n",
    "def get_average_performance(df, trainfunc):\n",
    "    aucscores = []\n",
    "    fscores = []\n",
    "    for i in range(100):\n",
    "        tmpf1, tmpauc = trainfunc(df)\n",
    "        fscores += [tmpf1]\n",
    "        aucscores += [tmpauc]\n",
    "    return(np.average(fscores), 2*np.std(fscores), np.average(aucscores), 2*np.std(aucscores))\n",
    "\n",
    "# Get the average performance across 100 runs for a given kNN training model\n",
    "def get_average_knn_performance(df, trainfunc, neighbors):\n",
    "    aucscores = []\n",
    "    fscores = []\n",
    "    for i in range(100):\n",
    "        tmpf1, tmpauc = trainfunc(df, neighbors)\n",
    "        fscores += [tmpf1]\n",
    "        aucscores += [tmpauc]\n",
    "    return(np.average(fscores), 2*np.std(fscores), np.average(aucscores), 2*np.std(aucscores))\n",
    "\n",
    "# Train on | Test on utility\n",
    "def cross_set_performance(df1, df2):\n",
    "    fscores = []\n",
    "    aucscores = []\n",
    "    for i in range(100): #sort of a bootstrap; captures model instability; takes a while\n",
    "        lr = LogisticRegression(penalty='l2')\n",
    "        tmpvecs, tmplabs = shuffle(np.asarray(df1.iloc[:,2:]), np.asarray(df1.Label))\n",
    "        lr.fit(tmpvecs, tmplabs)\n",
    "        fscores += [f1_score(df2.Label, lr.predict(df2.iloc[:,2:]))]\n",
    "        aucscores += [roc_auc_score(df2.Label, lr.predict_proba(df2.iloc[:,2:])[:,1])]\n",
    "    return(np.average(fscores), 2*np.std(fscores), np.average(aucscores), 2*np.std(aucscores))\n",
    "\n",
    "# Get tSNE for visualization and put into df\n",
    "def get_tsne(df, learning_rate=700.0, perplexity=30, locs=[2,2050]):\n",
    "    tsner = TSNE(learning_rate=learning_rate, perplexity=perplexity, n_iter=5000)\n",
    "    tsned = tsner.fit_transform(np.asarray(df.iloc[:,locs[0]:locs[1]]))\n",
    "    visdf = df.iloc[:,:locs[0]]\n",
    "    visdf.insert(1, 'ADE', [x.split('*')[1] for x in visdf['Query']])\n",
    "    visdf.insert(1, 'Drug', [x.split('*')[0] for x in visdf['Query']])\n",
    "    visdf.insert(4, 'tSNEy', tsned[:,1])\n",
    "    visdf.insert(4, 'tSNEx', tsned[:,0])\n",
    "    return visdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ESP Data\n",
    "omop = loaddata('subsetvecs/text/OMOPquery_subset.txt','startlists/OMOPlabsandqueries.txt')\n",
    "euadr = loaddata('subsetvecs/text/euadr_subset.txt','startlists/euadrreflabsandqueries.txt')\n",
    "#EU-ADR has some overlap with OMOP; we'll remove those\n",
    "euadrnot = euadr[~euadr.Query.isin(omop.Query)]\n",
    "#And vice versa\n",
    "omopnot = omop[~omop.Query.isin(euadr.Query)]\n",
    "\n",
    "#Load PSI Data\n",
    "psiomop = loaddata('subsetvecs/text/psiomop_subset.txt', 'startlists/OMOPlabsandqueries.txt')\n",
    "psieuadr = loaddata('subsetvecs/text/psieuadr_subset.txt', 'startlists/euadrreflabsandqueries.txt')\n",
    "#EU-ADR has some overlap with OMOP; we'll remove those\n",
    "psieuadrnot = psieuadr[~psieuadr.Query.isin(psiomop.Query)]\n",
    "#And vice versa\n",
    "psiomopnot = psiomop[~psiomop.Query.isin(psieuadr.Query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a quick LOO and S5F internal test for each reference set\n",
    "# The variancetest.py script finds the average 100 repetitions (not shown here)\n",
    "# Variance in LOO in this script is the variance of the models as a result of \n",
    "# random initiliazition of starting weights\n",
    "# LOO scripts require not insignificant computation time (order of hours) so only\n",
    "# a quick test is done here\n",
    "# LOO kNN does not have any variance, as the nearest neighbors are constant\n",
    "# For tests, the overall F1 metric and overall ROC AUC score are computed\n",
    "# LOO tests here for OMOP will take on the order of 10s of minutes to run, depending on hardware\n",
    "# LOO tests are commented out just for speed considerations; uncomment if desired\n",
    "\n",
    "\n",
    "#print(\"OMOP F1 Score LOO: {:.3f}\".format(lootest(omop))) # this will take a while to run\n",
    "print(\"OMOP F1 Score S5F: {:.3f} \\nOMOP AUC Score S5F: {:.3f}\\n\".format(*skftest(omop)))\n",
    "#print(\"OMOP PSI F1 Score LOO: {:.3f}\".format(lootest(psiomop))) # this will take a while to run\n",
    "print(\"OMOP PSI F1 Score S5F: {:.3f} \\nOMOP PSI AUC Score S5F: {:.3f}\\n\".format(*skftest(psiomop)))\n",
    "#print(\"EUADR F1 Score LOO: {:.3f}\".format(lootest(euadr))) # this will take a while to run\n",
    "print(\"EUADR F1 Score S5F: {:.3f} \\nEUADR AUC Score S5F: {:.3f}\\n\".format(*skftest(euadr)))\n",
    "#print(\"EUADR PSI F1 Score LOO: {:.3f}\".format(lootest(psieuadr))) # this will take a while to run\n",
    "print(\"EUADR PSI F1 Score S5F: {:.3f} \\nEUADR PSI AUC Score S5F: {:.3f}\".format(*skftest(psieuadr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do a much longer test to capture average performance of models across a variety of conditions.\n",
    "# This script can be used to regenerate the results in Table 1, simply run the function with the \n",
    "# appropriate arguments.\n",
    "# We do not need to do a variability test for LOO kNN, as the neighbors for LOO are invariant, so the results are \n",
    "# always the same\n",
    "# LOO variation for LR models capture variability in gradient descent and weight parameter initialization\n",
    "# These runs, especially for LOO, can take on the order of hours to run each one.\n",
    "\n",
    "print('Average F1: {:.3f} +/- {:.3f}\\nAverage AUC: {:.3f} +/- {:.3f}'.format(*get_average_performance(omop, skftest)))\n",
    "#print('Average F1: {:.3f} +/- {:.3f}\\nAverage AUC: {:.3f} +/- {:.3f}'.format(*get_average_knn_performance(omop, \n",
    "#                                                                                                          skfknntest, 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the performance like testing on EUADR?\n",
    "print('Training on OMOP, testing on EUADR (ESP):')\n",
    "print(\"F1 Score: {:.3f} +/- {:.3f}\\nAUC Score: {:.3f} +/- {:.3f}\".format(*cross_set_performance(omop, euadrnot)))\n",
    "print('Training on OMOP, testing on EUADR (PSI):')\n",
    "print(\"F1 Score: {:.3f} +/- {:.3f}\\nAUC Score: {:.3f} +/- {:.3f}\".format(*cross_set_performance(psiomop, psieuadrnot)))\n",
    "# What's the performance like testing on OMOP, training EUADR?\n",
    "print('Training on EUADR, testing on OMOP (ESP):')\n",
    "print(\"F1 Score: {:.3f} +/- {:.3f}\\nAUC Score: {:.3f} +/- {:.3f}\".format(*cross_set_performance(euadr, omopnot)))\n",
    "print('Training on EUADR, testing on OMOP (PSI):')\n",
    "print(\"F1 Score: {:.3f} +/- {:.3f}\\nAUC Score: {:.3f} +/- {:.3f}\".format(*cross_set_performance(psieuadr, psiomopnot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which ones does it get right (quickly training a single model)? \n",
    "# It gets a lot right, including side-effects it hasn't seen before\n",
    "omoplr = LogisticRegression(penalty='l1')\n",
    "tmpvecs, tmplabs = shuffle(np.asarray(omop.iloc[:,2:]), np.asarray(omop.Label))\n",
    "omoplr.fit(tmpvecs, tmplabs)\n",
    "correctlist = zip(euadrnot['Label'], omoplr.predict(euadrnot.iloc[:,2:]), euadrnot.Query)\n",
    "print(f'{\"Query \":>50} {\"Predicted\":^9}   {\"True\":^5}')\n",
    "counterthing = 1 # I know this is ugly, but it works for keeping the output short\n",
    "for i in correctlist:\n",
    "    if counterthing <= 10: # just truncated to ten for brevity\n",
    "        if i[0] == i[1]:\n",
    "            print(f\"{i[2]:>50} {i[0]:^9}   {i[1]:^5}\")\n",
    "            counterthing += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which ones does it get wrong (same model as before)? \n",
    "# It gets some wrong in side-effects it has seen before\n",
    "incorrectlist = zip(euadrnot.Label, omoplr.predict(euadrnot.iloc[:,2:]), euadrnot.Query)\n",
    "print(f'{\"Query \":>50} {\"Predicted\":^9}   {\"True\":^5}')\n",
    "counterthing = 1 \n",
    "for i in incorrectlist:\n",
    "    if counterthing <= 10: # just truncated to ten for brevity\n",
    "        if i[0] != i[1]:\n",
    "            print(f\"{i[2]:>50} {i[0]:^9}   {i[1]:^5}\")\n",
    "            counterthing += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total correct on per ADE basis\n",
    "predicted = omoplr.predict(euadrnot.iloc[:,2:])\n",
    "adeperf = {k: [] for k in np.unique([x.split('*')[1] for x in euadrnot.Query])} \n",
    "for indx, i in enumerate(euadrnot.Query):\n",
    "    if predicted[indx] == np.asarray(euadrnot.Label)[indx]:\n",
    "        adeperf[i.split('*')[1]] += [1]\n",
    "    else:\n",
    "        adeperf[i.split('*')[1]] += [0]\n",
    "for i in adeperf:\n",
    "    print(f\"{i:>30}: {np.average(adeperf[i]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a non-duplicate OMOP + ADIS dataframe\n",
    "nodups = pd.concat([omop, euadrnot])\n",
    "psinodups = pd.concat([psiomop, psieuadrnot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How do we do with LOO on this? With Stratified 5 Fold?\n",
    "\n",
    "#print(lootest(nodups)) #this trains 480 models; takes a while, so commented out since S5F is extremely similar perf\n",
    "print('Average F1: {:.3f} +/- {:.3f}\\nAverage AUC: {:.3f} +/- {:.3f}'.format(*get_average_performance(nodups, skftest)))\n",
    "\n",
    "# It does very well. In fact, it does better in LOO (usually) than OMOP does\n",
    "# More importantly perhaps, we do much better than training on OMOP and testing on ADIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up for AUC and AUC graphs\n",
    "from scipy import interp\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "def skfrocauc(vecs, labels):\n",
    "    aucs = []\n",
    "    tprs = []\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    for train,test in StratifiedKFold(n_splits=5, shuffle=True).split(vecs, labels):\n",
    "        model = LogisticRegression(penalty='l1')\n",
    "        model.fit(vecs[train], labels[train])\n",
    "        probas_ = model.predict_proba(vecs[test])[:,1]\n",
    "        fpr, tpr, thresholds = roc_curve(labels[test], probas_, pos_label=1)\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs += [auc(fpr, tpr)]\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    return mean_tpr, mean_fpr, mean_auc, aucs\n",
    "\n",
    "def loorocauc(df):\n",
    "    tmpdf = df.iloc[:,:2]\n",
    "    vecs = np.asarray(df.iloc[:,2:])\n",
    "    labels = np.asarray(df.Label)\n",
    "    for train,test in LeaveOneOut().split(vecs):\n",
    "        model = LogisticRegression(penalty='l1')\n",
    "        model.fit(vecs[train], labels[train])\n",
    "        tmpdf.loc[test, 'Prob'] = model.predict_proba(vecs[test])[:,1]\n",
    "    return tmpdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omoptpr, omopfpr, omopmeanauc, omopaucs = skfrocauc(np.asarray(omop.iloc[:,2:]), np.asarray(omop.Label))\n",
    "print(omopmeanauc)\n",
    "psiomoptpr, psiomopfpr, psiomopmeanauc, psiomopaucs = skfrocauc(np.asarray(psiomop.iloc[:,2:]), np.asarray(psiomop.Label))\n",
    "print(psiomopmeanauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOO AUC calculations take a while (~30min maybe?), on account of the number of models required to train\n",
    "loomop = loorocauc(omop) \n",
    "psiloomop = loorocauc(psiomop)\n",
    "loofpr, lootpr, _ = roc_curve(np.asarray(loomop.Label), np.asarray(loomop.Prob), pos_label=1)\n",
    "psiloofpr, psilootpr, _ = roc_curve(np.asarray(psiloomop.Label), np.asarray(psiloomop.Prob), pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "\n",
    "# Generate per side-effect curves ESP\n",
    "miloofpr, milootpr, _ = roc_curve(np.asarray(loomop[loomop.Query.str.contains('myocardial')].Label), \n",
    "                                  np.asarray(loomop[loomop.Query.str.contains('myocardial')].Prob), \n",
    "                                  pos_label=1)\n",
    "kiloofpr, kilootpr, _ = roc_curve(np.asarray(loomop[loomop.Query.str.contains('kidney')].Label), \n",
    "                                  np.asarray(loomop[loomop.Query.str.contains('kidney')].Prob), \n",
    "                                  pos_label=1)\n",
    "giloofpr, gilootpr, _ = roc_curve(np.asarray(loomop[loomop.Query.str.contains('gastrointestinal')].Label), \n",
    "                                  np.asarray(loomop[loomop.Query.str.contains('gastrointestinal')].Prob), \n",
    "                                  pos_label=1)\n",
    "liloofpr, lilootpr, _ = roc_curve(np.asarray(loomop[loomop.Query.str.contains('liver')].Label), \n",
    "                                  np.asarray(loomop[loomop.Query.str.contains('liver')].Prob), \n",
    "                                  pos_label=1)\n",
    "\n",
    "# Generate per side-effect curves PSI\n",
    "pmiloofpr, pmilootpr, _ = roc_curve(np.asarray(psiloomop[psiloomop.Query.str.contains('myocardial')].Label), \n",
    "                                  np.asarray(psiloomop[psiloomop.Query.str.contains('myocardial')].Prob), \n",
    "                                  pos_label=1)\n",
    "pkiloofpr, pkilootpr, _ = roc_curve(np.asarray(psiloomop[psiloomop.Query.str.contains('kidney')].Label), \n",
    "                                  np.asarray(psiloomop[psiloomop.Query.str.contains('kidney')].Prob), \n",
    "                                  pos_label=1)\n",
    "pgiloofpr, pgilootpr, _ = roc_curve(np.asarray(psiloomop[psiloomop.Query.str.contains('gastrointestinal')].Label), \n",
    "                                  np.asarray(psiloomop[psiloomop.Query.str.contains('gastrointestinal')].Prob), \n",
    "                                  pos_label=1)\n",
    "pliloofpr, plilootpr, _ = roc_curve(np.asarray(psiloomop[psiloomop.Query.str.contains('liver')].Label), \n",
    "                                  np.asarray(psiloomop[psiloomop.Query.str.contains('liver')].Prob), \n",
    "                                  pos_label=1)\n",
    "\n",
    "# Set up 2x2 plot space\n",
    "plt.figure(1, figsize=(15,10), dpi=200)\n",
    "\n",
    "def startat0(arr):\n",
    "    return np.insert(arr, 0, 0.0) #just to make sure that the graph starts at 0,0\n",
    "\n",
    "#Plot Myocardial Infarction\n",
    "plt.subplot(231)\n",
    "plt.subplot(231).spines['top'].set_visible(False)\n",
    "plt.subplot(231).spines['right'].set_visible(False)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.plot(startat0(miloofpr), startat0(milootpr), label=f'ESP (AUC = {auc(miloofpr, milootpr):3.2f})',\n",
    "        color='DarkSlateGray', alpha=0.95, solid_joinstyle='bevel')\n",
    "plt.plot(startat0(pmiloofpr), startat0(pmilootpr), label=f'PSI  (AUC = {auc(pmiloofpr, pmilootpr):3.2f})',\n",
    "        color='SkyBlue', alpha=0.95, solid_joinstyle='bevel')\n",
    "plt.yscale('linear')\n",
    "plt.title('Myocardial Infarction')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(False)\n",
    "\n",
    "#Plot GIBleed\n",
    "plt.subplot(232)\n",
    "plt.subplot(232).spines['top'].set_visible(False)\n",
    "plt.subplot(232).spines['right'].set_visible(False)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.plot(startat0(giloofpr), startat0(gilootpr), label=f'ESP (AUC = {auc(giloofpr, gilootpr):3.2f})',\n",
    "        color='DarkSlateGray', alpha=0.95, solid_joinstyle='bevel')\n",
    "plt.plot(startat0(pgiloofpr), startat0(pgilootpr), label=f'PSI  (AUC = {auc(pgiloofpr, pgilootpr):3.2f})',\n",
    "        color='SkyBlue', alpha=0.95, solid_joinstyle='bevel')\n",
    "plt.yscale('linear')\n",
    "plt.title('Gastrointestinal Bleed')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(False)\n",
    "\n",
    "#Plot Combined Curve\n",
    "plt.subplot(233)\n",
    "plt.subplot(233).spines['top'].set_visible(False)\n",
    "plt.subplot(233).spines['right'].set_visible(False)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.plot(omopfpr, omoptpr, label=f'ESP S5F  (AUC {omopmeanauc:3.2f} +/- {2*np.std(omopaucs):3.2f})',\n",
    "        color='Gray', alpha=0.75, solid_joinstyle='bevel')\n",
    "plt.plot(loofpr, lootpr, label=f'ESP LOO (AUC {auc(loofpr, lootpr):3.2f})',\n",
    "        color='DarkSlateGray', alpha=0.75, solid_joinstyle='bevel')\n",
    "plt.plot(psiomopfpr, psiomoptpr, label=f'PSI S5F   (AUC {psiomopmeanauc:3.2f} +/- {2*np.std(psiomopaucs):3.2f})',\n",
    "        color='SkyBlue', alpha=0.75, solid_joinstyle='bevel')\n",
    "plt.plot(psiloofpr, psilootpr, label=f'PSI LOO  (AUC {auc(psiloofpr, psilootpr):3.2f})',\n",
    "        color='#166483', alpha=0.75, solid_joinstyle='bevel')\n",
    "plt.yscale('linear')\n",
    "plt.title('Full OMOP Set')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(False)\n",
    "\n",
    "#Plot Liver Injury\n",
    "plt.subplot(234)\n",
    "plt.subplot(234).spines['top'].set_visible(False)\n",
    "plt.subplot(234).spines['right'].set_visible(False)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.plot(startat0(liloofpr), startat0(lilootpr), label=f'ESP (AUC = {auc(liloofpr, lilootpr):3.2f})',\n",
    "        color='DarkSlateGray', alpha=0.95, solid_joinstyle='bevel')\n",
    "plt.plot(startat0(pliloofpr), startat0(plilootpr), label=f'PSI  (AUC = {auc(pliloofpr, plilootpr):3.2f})',\n",
    "        color='SkyBlue', alpha=0.95, solid_joinstyle='bevel')\n",
    "plt.yscale('linear')\n",
    "plt.title('Acute Liver Injury')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(False)\n",
    "plt.text(-0.25, 1.35,'True Positive Rate', rotation='vertical', fontsize=12)\n",
    "plt.text(.9, -0.2,'False Positive Rate', fontsize=12)\n",
    "\n",
    "#Plot Kidney Injury\n",
    "plt.subplot(235)\n",
    "plt.subplot(235).spines['top'].set_visible(False)\n",
    "plt.subplot(235).spines['right'].set_visible(False)\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.plot(startat0(kiloofpr), startat0(kilootpr), label=f'ESP (AUC = {auc(kiloofpr, kilootpr):3.2f})',\n",
    "        color='DarkSlateGray', alpha=0.95, solid_joinstyle='bevel')\n",
    "plt.plot(startat0(pkiloofpr), startat0(pkilootpr), label=f'PSI  (AUC = {auc(pkiloofpr, pkilootpr):3.2f})',\n",
    "        color='SkyBlue', alpha=0.95, solid_joinstyle='bevel')\n",
    "plt.yscale('linear')\n",
    "plt.title('Acute Kidney Injury')\n",
    "plt.grid(False)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh import palettes\n",
    "nodupsvis = get_tsne(nodups, 200.0, 30, [2, 32000]) # Will likely be some variability in these, but overall consistent trends\n",
    "adelabs = [''.join([x[0], x[1]]) for x in zip(nodupsvis.ADE, np.asarray(nodupsvis.Label,dtype=str))]\n",
    "colormap = dict(zip(sorted(list(np.unique(adelabs)) + ['S(diseases_of_mitral_valve)1'], reverse=True), palettes.Category20[20]))\n",
    "colormap\n",
    "colors = [colormap[x] for x in adelabs]\n",
    "nodupsvis.insert(6, 'Color', colors)\n",
    "nodupsvis.insert(7, 'ADEleg', [x.split(')')[0].split('(')[1].replace('_', ' ').title() for x in nodupsvis.ADE])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models.sources import ColumnDataSource\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "panels = []\n",
    "p=figure(title='OMOP + EU-ADR by ADE', plot_width=950, plot_height=600)\n",
    "for i in np.unique(nodupsvis.ADE):\n",
    "    p.circle(x='tSNEx', y='tSNEy', source=ColumnDataSource(nodupsvis[nodupsvis.ADE == i]), color='Color', size=10, alpha=0.9, legend='ADEleg')\n",
    "    tmpfig = figure(title='OMOP + EU-ADR: {}'.format(np.unique(nodupsvis[nodupsvis.ADE==i].ADEleg)[0]), plot_width=950, plot_height=600)\n",
    "    tmpfig.circle(x='tSNEx', y='tSNEy', source = ColumnDataSource(nodupsvis[nodupsvis.ADE == i]), color='Color', size=10, alpha=0.9, legend='Label')\n",
    "    tmpfig.add_tools(HoverTool(tooltips=[(\"Drug\", \"@Drug\"), (\"Label\", \"@Label\")]))\n",
    "    tmpfig.legend.location=\"top_right\"\n",
    "    tmpfig.legend.click_policy = 'hide'\n",
    "    tmpfig.grid.visible=False\n",
    "    tmpfig.xaxis.visible=False\n",
    "    tmpfig.yaxis.visible=False\n",
    "    panels += [Panel(child=tmpfig, title='{}'.format(np.unique(nodupsvis[nodupsvis.ADE==i].ADEleg)[0]))]\n",
    "p.add_tools(HoverTool(tooltips=[(\"Drug\", \"@Drug\"), (\"ADE\",\"@ADE\"), (\"Label\", \"@Label\")]))\n",
    "p.legend.location = 'top_right'\n",
    "p.legend.click_policy = 'hide'\n",
    "p.grid.visible=False\n",
    "p.xaxis.visible=False\n",
    "p.yaxis.visible=False\n",
    "panels.insert(0, Panel(child=p, title=\"Full Set\"))\n",
    "tabs = Tabs(tabs=panels)\n",
    "show(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadsiderdata(inputfile):\n",
    "    sidervecs = []\n",
    "    siderqueries = []\n",
    "    with open(inputfile,'r') as infile:\n",
    "        infile.readline()\n",
    "        for line in infile:\n",
    "            tmp = line.strip().split('|')\n",
    "            sidervecs += [bitarray(tmp[1])]\n",
    "            siderqueries += [tmp[0]]\n",
    "    sidervecs = np.asarray(sidervecs, dtype=int)\n",
    "\n",
    "    siderdf = pd.DataFrame(sidervecs)\n",
    "    siderdf.columns = [str(x) for x in range(1,32001)]\n",
    "    siderdf.insert(0, 'Query', siderqueries)\n",
    "    return siderdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toppreds(trainset, testset):\n",
    "    regressor = LogisticRegression(C=1, penalty='l2')\n",
    "    regressor.fit(np.asarray(trainset.iloc[:,2:]), np.asarray(trainset['Label']))\n",
    "    probs = regressor.predict_proba(np.asarray(testset.iloc[:,1:]))\n",
    "    return sorted(zip(probs[:,1], np.asarray(testset['Query'])), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sider = loadsiderdata('subsetvecs/text/noOMOPnoMEDIfullsider_subset.txt')\n",
    "misider = sider[sider.Query.str.contains('myocardial')]\n",
    "gisider = sider[sider.Query.str.contains('gastro')]\n",
    "lisider = sider[sider.Query.str.contains('liver')]\n",
    "kisider = sider[sider.Query.str.contains('kidney')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we get rofecoxib? Sub drug of choice at leisure\n",
    "for i in toppreds(omop[omop.Query.str.contains('myocardial')], misider):\n",
    "    if 'rofecoxib' in i[1]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top ten predictions from one model for myocardial infarction?\n",
    "toppreds(omop, misider)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture mioutput\n",
    "# In order to get a little bit more stability / reproducibility\n",
    "# we'll look at the things which show up most often in the top 30 for each ADE\n",
    "\n",
    "tmpdict = dict()\n",
    "for i in range(1000): # maybe not completely necessary to do 1k iterations\n",
    "    for thing in toppreds(omop, misider)[:30]:\n",
    "        try:\n",
    "            tmpdict[thing[1]] += [thing[0]]\n",
    "        except KeyError:\n",
    "            tmpdict[thing[1]] = [thing[0]]\n",
    "        \n",
    "for i in tmpdict:\n",
    "    tmpdict[i] = [np.average(tmpdict[i]), len(tmpdict[i])]\n",
    "\n",
    "sorted(tmpdict.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mioutput.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture gioutput\n",
    "# In order to get a little bit more stability / reproducibility\n",
    "# we'll look at the things which show up most often in the top 30 for each ADE\n",
    "\n",
    "tmpdict = dict()\n",
    "for i in range(1000):\n",
    "    for thing in toppreds(omop, gisider)[:30]:\n",
    "        try:\n",
    "            tmpdict[thing[1]] += [thing[0]]\n",
    "        except KeyError:\n",
    "            tmpdict[thing[1]] = [thing[0]]\n",
    "        \n",
    "for i in tmpdict:\n",
    "    tmpdict[i] = [np.average(tmpdict[i]), len(tmpdict[i])]\n",
    "\n",
    "sorted(tmpdict.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gioutput.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture lioutput\n",
    "# In order to get a little bit more stability / reproducibility\n",
    "# we'll look at the things which show up most often in the top 30 for each ADE\n",
    "\n",
    "tmpdict = dict()\n",
    "for i in range(1000):\n",
    "    for thing in toppreds(omop, lisider)[:30]:\n",
    "        try:\n",
    "            tmpdict[thing[1]] += [thing[0]]\n",
    "        except KeyError:\n",
    "            tmpdict[thing[1]] = [thing[0]]\n",
    "        \n",
    "for i in tmpdict:\n",
    "    tmpdict[i] = [np.average(tmpdict[i]), len(tmpdict[i])]\n",
    "\n",
    "sorted(tmpdict.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lioutput.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture kioutput\n",
    "# In order to get a little bit more stability / reproducibility\n",
    "# we'll look at the things which show up most often in the top 30 for each ADE\n",
    "\n",
    "tmpdict = dict()\n",
    "for i in range(1000):\n",
    "    for thing in toppreds(omop, kisider)[:30]:\n",
    "        try:\n",
    "            tmpdict[thing[1]] += [thing[0]]\n",
    "        except KeyError:\n",
    "            tmpdict[thing[1]] = [thing[0]]\n",
    "        \n",
    "for i in tmpdict:\n",
    "    tmpdict[i] = [np.average(tmpdict[i]), len(tmpdict[i])]\n",
    "\n",
    "sorted(tmpdict.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kioutput.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
